{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import googletrans\n",
    "import pygoogletranslation\n",
    "# from google_trans_new import google_translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory\n",
    "DATA_DIR = \"./\"\n",
    "\n",
    "# read train and test csv files\n",
    "train_df = pd.read_csv(os.path.join(DATA_DIR, \"translated_train_text.csv\"))\n",
    "test_df = pd.read_csv(os.path.join(DATA_DIR, \"translated_test_dataset.csv\"))\n",
    "\n",
    "# instantiate translator\n",
    "# translator = google_translator()\n",
    "translator = googletrans.Translator()#service_urls=['translate.googleapis.com','translate.google.com','translate.google.co.kr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to translate sentence\n",
    "def translate_sentence(sentence, src_lang=None):\n",
    "    if \"en\" == src_lang:        \n",
    "        return sentence\n",
    "\n",
    "    src_lang = \"zh-cn\" if \"zh\" in src_lang else src_lang\n",
    "    translated_sentence = translator.translate(sentence, src=src_lang, dest='en')\n",
    "\n",
    "    return translated_sentence.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_translate_for_other_language(num = [0,500]):\n",
    "    print(\"Running: \", num)\n",
    "    ## translation for training data \n",
    "    for index, row in tqdm(train_df.iterrows()):\n",
    "        if index < num[0] or index > num[1]:\n",
    "            continue\n",
    "        else:\n",
    "#             time.sleep(1)\n",
    "            # translate premise sentence train set\n",
    "            train_df.loc[index, \"premise_translated\"] = translate_sentence(row['premise'], row[\"lang_abv\"])\n",
    "            # translate hypothesis sentence train set\n",
    "#             time.sleep(1)\n",
    "            train_df.loc[index, \"hypothesis_translated\"] = translate_sentence(row['hypothesis'], row[\"lang_abv\"])\n",
    "#             time.sleep(1)\n",
    "\n",
    "\n",
    "    file_name = r'translated_train_text.csv'\n",
    "    ## save translated dataframe\n",
    "    train_df.to_csv(file_name, index=False)\n",
    "    print(f\"Translated train dataset saved in {file_name} csv file\")\n",
    "    ## translation for testing data\n",
    "#     time.sleep(5)\n",
    "#     for index, row in tqdm(test_df.iterrows()):\n",
    "#         if index < num[0] or index > num[1]:\n",
    "#             continue\n",
    "#         else:\n",
    "# #             time.sleep(2)\n",
    "#             # translate premise sentence train set\n",
    "#             test_df.loc[index, \"premise_translated\"] = translate_sentence(row['premise'], row[\"lang_abv\"])\n",
    "# #             time.sleep(2)\n",
    "#             # translate hypothesis sentence train set\n",
    "#             test_df.loc[index, \"hypothesis_translated\"] = translate_sentence(row['hypothesis'], row[\"lang_abv\"])\n",
    "# #             time.sleep(2)\n",
    "\n",
    "\n",
    "    file_name = r'translated_test_dataset.csv'\n",
    "    ## save translated dataframe\n",
    "    train_df.to_csv(file_name, index=False)\n",
    "    print(f\"Translated test dataset saved in {file_name} csv file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2119it [00:00, 10809.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running:  [12000, 12200]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12120it [00:44, 274.15it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translated train dataset saved in translated_train_text.csv csv file\n",
      "Translated test dataset saved in translated_test_dataset.csv csv file\n"
     ]
    }
   ],
   "source": [
    "generate_translate_for_other_language(num = [12000, 12200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# translator.translate('ریاست ہائے متحدہ امریکہ واپس آنے پر، ہج ایف بی آئی کے ایجنٹوں کے ذریعے ہوائی اڈے پر ملاقات کی، تحقیقات کی، اور اگلے دن وفاقی گرین جوری سے پہلے اسامہ بن لادن کی تحقیقات سے ملاقات کی.', lang_tgt='en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sent=translator.translate('veritas lux mea', src='la')\n",
    "# print(sent)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
